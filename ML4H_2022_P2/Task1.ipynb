{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0754c2",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# various nltk elements that's needed for preprocessing\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d231a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from src.hyperparameter_search import run_randomized_search\n",
    "from src.evaluate import train_and_eval_clf\n",
    "from src.embeddings import fit_tf_idf\n",
    "from src.data_processing import preprocess_raw_datasets, PreprocessingOptions, get_raw_x_y\n",
    "from src.data_loading import load_raw_datasets, persist_preprocessed_data, load_preprocessed_data, load_data, persist_labels, load_labels\n",
    "\n",
    "from src.constants import PATH_DEV_DATA, PATH_TEST_DATA, PATH_TRAIN_DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4f962",
   "metadata": {},
   "source": [
    "# Data Loading & Preprocessing\n",
    "Takes some time, but needs to be done only once! Otherwise just load the preprocessed data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81de68",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3270e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSING_OPTIONS = PreprocessingOptions(remove_stop_words=False, lemmatisation=False)\n",
    "PREPROCESSED_DATA_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf45398",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESSED_DATA_AVAILABLE:\n",
    "    x_preprocessed_train = load_preprocessed_data(PREPROCESSING_OPTIONS, \"train\")\n",
    "    x_preprocessed_dev = load_preprocessed_data(PREPROCESSING_OPTIONS, \"dev\")\n",
    "    x_preprocessed_test = load_preprocessed_data(PREPROCESSING_OPTIONS, \"test\")\n",
    "    \n",
    "    y_train, y_dev, y_test = load_labels()\n",
    "    \n",
    "else:\n",
    "    train, dev, test = load_raw_datasets()\n",
    "    x_preprocessed_train, y_train, x_preprocessed_dev, y_dev, x_preprocessed_test, y_test = preprocess_raw_datasets(train, dev, test, PREPROCESSING_OPTIONS)\n",
    "\n",
    "    # save preprocessed data\n",
    "    persist_preprocessed_data(x_preprocessed_train, PREPROCESSING_OPTIONS, \"train\")\n",
    "    persist_preprocessed_data(x_preprocessed_dev, PREPROCESSING_OPTIONS, \"dev\")\n",
    "    persist_preprocessed_data(x_preprocessed_test, PREPROCESSING_OPTIONS, \"test\")\n",
    "    \n",
    "    # save labels\n",
    "    persist_labels(y_train, y_dev, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877c01a",
   "metadata": {},
   "source": [
    "# TF-IDF embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31807fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = fit_tf_idf(x_preprocessed_train)\n",
    "\n",
    "x_tfidf_train = tfidf.transform(x_preprocessed_train)\n",
    "x_tfidf_dev = tfidf.transform(x_preprocessed_dev)\n",
    "x_tfidf_test = tfidf.transform(x_preprocessed_test)\n",
    "\n",
    "assert x_tfidf_train.shape[0] == len(y_train)\n",
    "assert x_tfidf_dev.shape[0] == len(y_dev)\n",
    "assert x_tfidf_test.shape[0] == len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341e648",
   "metadata": {},
   "source": [
    "# Training Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa07d3",
   "metadata": {},
   "source": [
    "# Baseline 1: Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd4bb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_and_eval_clf(MultinomialNB(), x_tfidf_train, y_train, x_tfidf_dev, y_dev, x_tfidf_test, y_test, \"Naive Bayes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d2bf3",
   "metadata": {},
   "source": [
    "# Baseline 2: Linear SVM model\n",
    "Linear classifiers are generally well suited for high dimensional data, so they are a reasonable choice for TFIDF embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1630f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_and_eval_clf(SGDClassifier(random_state=0, max_iter=10), x_tfidf_train, y_train, x_tfidf_dev, y_dev, x_tfidf_test, y_test, \"Linear SVM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9fca9",
   "metadata": {},
   "source": [
    "## Hyperparameter search for Linear Models\n",
    "Hinge loss - Corresponds to linear SVM\n",
    "\n",
    "Log loss - Corresponds to Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_HYPERPARAMETER_SEARCH = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if RUN_HYPERPARAMETER_SEARCH:\n",
    "    \n",
    "    distributions = {\n",
    "\n",
    "        \"loss\": [\"hinge\", \"log\"],\n",
    "        \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"alpha\": [0.0001, 0.000001],\n",
    "        \"class_weight\": [\"balanced\", None],\n",
    "        \"early_stopping\": [True]\n",
    "\n",
    "    }\n",
    "\n",
    "    # Concatenate the train and dev sets to use for kfold\n",
    "    train_and_dev_tfidf = vstack([x_tfidf_train, x_tfidf_dev])\n",
    "    y_train_and_dev = np.concatenate([y_train, y_dev])\n",
    "    assert train_and_dev_tfidf.shape[0] == x_tfidf_train.shape[0] + x_tfidf_dev.shape[0]\n",
    "    assert len(y_train_and_dev) == len(y_train) + len(y_dev)\n",
    "\n",
    "    results, best_params_linear, best_score = run_randomized_search(SGDClassifier(random_state=0), \"Linear_Models_\" + PREPROCESSING_OPTIONS.get_current_options(),\n",
    "                                                                 train_and_dev_tfidf, y_train_and_dev, distributions, n_iter=25, cv=4, random_state=0, n_jobs=4)\n",
    "\n",
    "    # display results\n",
    "    display(results[[column for column in results.columns if column not in [\"std_fit_time\", \"mean_score_time\", \"std_score_time\", \"params\"]]])\n",
    "\n",
    "else:\n",
    "    # set best params manually\n",
    "    best_params_linear = {\n",
    "        \"penalty\": \"l2\",\n",
    "        \"loss\": \"log\",\n",
    "        \"early_stopping\": True,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"alpha\": 0.000001\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c911ae8",
   "metadata": {},
   "source": [
    "## Best hyperparams linear classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f83bdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_and_eval_clf(SGDClassifier(random_state=0, **best_params_linear), x_tfidf_train, y_train, x_tfidf_dev, y_dev, x_tfidf_test, y_test, \"Linear Models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585ed55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4h_project2",
   "language": "python",
   "name": "ml4h_project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
